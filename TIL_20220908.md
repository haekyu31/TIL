# TIL

## DataScience
### seq2seq 
* https://towardsdatascience.com/day-1-2-attention-seq2seq-models-65df3f49e263
- ![image](https://wikidocs.net/images/page/24996/%EC%9D%B8%EC%BD%94%EB%8D%94%EB%94%94%EC%BD%94%EB%8D%94%EB%AA%A8%EB%8D%B8.PNG)
- ![image](https://miro.medium.com/max/875/1*1nERP8YPd-0DkpVC4Fi2pg.png)
    input is a series of words, and the output is the translated series of words.<br>
    The model is composed of an encoder and a decoder. The encoder captures the context of the input sequence in the form of a hidden state vector and sends it to the decoder, which then produces the output sequence. <br>
    RNNs by design, take two inputs, the current example they see, and a representation of the previous input. Thus, the output at time step t depends on the current input as well as the input at time t-1. This is the reason they perform better when posed with sequence related tasks. The sequential information is preserved in a hidden state of the network and used in the next instance.<br>


### generative model    
1. AutoEncoder
    vector or image
    Encoder -> 이미지를 작은 size로 압축하는것
    Decoder -> 압축된 작은 size의 값을 이미지로 되돌리는것
    :: Paired data가 필요함 -> Noise를 주거나, 중간에 구멍 뚫거나, 컬러->흑백으로 바꾸거나...

    ```python
    # This is the size of our encoded representations
    encoding_dim = 32  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats
    # (32,32)크기의 이미지를 784개의 vector형태로 바꾸기 
    # This is our input image
    input_img = tf.keras.Input(shape=(784,))

    # "encoded" is the encoded representation of the input
    encoded = tf.keras.layers.Dense(encoding_dim, activation='relu')(input_img)

    # "decoded" is the lossy reconstruction of the input
    decoded = layers.Dense(784, activation='sigmoid')(encoded)

    # This model maps an input to its reconstruction
    autoencoder = tf.keras.Model(input_img, decoded)
    ```
    ```python
    Model: "model_3"
    _________________________________________________________________
    Layer (type)                Output Shape              Param #   
    =================================================================
    input_5 (InputLayer)        [(None, 784)]             0         
                                                                    
    dense_6 (Dense)             (None, 32)                25120     
                                                                    
    dense_7 (Dense)             (None, 784)               25872     
                                                                    
    =================================================================
    Total params: 50,992
    Trainable params: 50,992
    Non-trainable params: 0
    _________________________________________________________________
    # Dense_6은 encoder된것 Dense_7 decoder된것 
    # This model maps an input to its encoded representation
    encoder = tf.keras.Model(input_img, encoded)

    # This is our encoded (32-dimensional) input
    encoded_input = tf.keras.Input(shape=(encoding_dim,))
    # Retrieve the last layer of the autoencoder model
    decoder_layer = autoencoder.layers[-1]
    # Create the decoder model
    decoder = tf.keras.Model(encoded_input, decoder_layer(encoded_input))
    ```
2. Variational Auto Encoder(VAE)
    Decoder는 Encoder가 압축해준 input 만 잘 decoding 함 (이미지로 복원함)
    -> Encoder의 output의 분포를 우리가 잘 아는 정규분포 (혹은 다른 분포)로 만들 수 있다면,
    우리가 임의로 Decoder의 input을 줄 수 있음 => 다양한 이미지를 우리 멋대로 만들 수 있다.
3. GAN
    Decoder (generator) + Discriminator (Classifier) -> 경쟁적으로 새로운 
    이미지를 생성하는 모델
   1. Noise -> 새로운 이미지 생성
   2. Discriminator 학습 (새로운 이미지 fake image vs 실제 이미지 real image)
   3. GAN [Generator + Discriminator] 학습 (하지만 Discriminator는 weight를 수정하지 않음)
    -> Generator가 Discriminator가 분류하지 못하는 방향으로 weight를 수정
    -> 학습 후, Generator는 real image와 거의 비슷한 이미지 생성
4. Cycle GAN
    : AutoEncoder 2개와 Discriminator 를 활용해서,
    paired data가 아닌 두개의 이미지 style을 바꾸는 GAN 알고리즘

-----
데이터를 던져 드리고 (의료데이터, 배그데이터.. 기타 등등)
-> 시간을 드리고
-> 제가 분석한 결과 ipynb을 공유
-> summary
1. 시각화
-> Boxplot (jitter, violin), Densitiy plot, scatter plot...
2. 통계 (두 군에 무슨 차이가 있다?)
-> t.test, wilcoxon test, chisq, fisher
-> Linear regression, Logistic regression
-> Pearson correlation (spearman, kendel)
3. 머신러닝 -> 성능지표에 대한 statistics..
<전처리 (scale, normalization)>
-> 추가적인 변수 만드는거
-> category가 매우 많은 변수들 control
-> outlier 제거..
-> 결측치 imputation (혹은 평균으로 채워주거나..)
<학습>
PyCaret..
XGBoost, Adaboost, CatBoost, RandomForest, Quantile Classifier...
4. 딥러닝
이미지 CNN, time series - RNN, 1D Conv, AutoEncoder, GAN