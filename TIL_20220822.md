# TIL

Classification의 종류
1. Binary classification<br>
 -> 2가지를 분류하는 것<br>
구현1: Sigmoid (unit 1) -> binary_crossentropy<br>
구현2: Softmax (Unit 2) -> categorical_crossentropy<br>
(공식에 대한 것은 블로그 참조)https://sosal.kr/1128 <br>
2. Multi-class classification<br>
-> N개의 class 중에서 '하나'를 고르는 것<br>
Softmax만 사용 (Unit N개) -> categorical_crossentropy -> 총합이 1<br>
[Accuracy]: 1000개중 하나 고르는 Task: 0.1% 70%<br>
'[Top5 accuracy]: Softmax값이 높은 5개 class 중 정답이 있냐 없냐'<br>
3. Multi-label classification<br>
-> N개의 Class 중에서 다중의 'Class'를 고르는 것<br>
-> Sigmoid (Unit N) -> binary_crossentropy<br>
Output class마다 0~1사이 값이 주어짐.<br>
   1) 코성형    -> 0 ~ 1 : Threshold: 0.2 (Sensitivity/Specificity) + ROC/AUC
   2) 라섹수술 -> 0 ~ 1 : Threshold: 0.5
   3) 눈썹문신 -> 0 ~ 1 : Threhsold: 0.7
   4) 탈모수술 -> 0 ~ 1 : Threshold: 0.3

Class activation map (CAM):<br>
-> 꼭 Global Average Pooling 쓴 이후 Prediction (sigmoid or softmax)<br>
<br>
GradCAM<br>
-> Weight를 실제로 logistic regression (sigmoid) 할때 만들어진 weight가 아닌,
Convolution layer의 output에 대한 gradient를 추론하여 (inference) CAM (heatmap)을 그린다.<br>
=> 장점은 GAP를 쓰지 않아도 되며, (마지막 conv layer가 아닌) 중간에 있는 conv layer까지 CAM을 그릴 수 있다.

## 중요한 개념 2가지
* Softmax (# Exponential 값의 전체 합 분의 Exponential 값 #ratio )
* Loss: categorical cross entropy
    - 가능하다면 CAM을 직접 구현해보기 까지..
    - GradCAM으로 다중의 conv에서 CAM을 그려보기 까지..

    - 데이터를 받는다.
    - 데이터의 구조를 확인하고, csv (meta data)의 구조를 파악한다.
    - tensorflow를 모두 import 하고 Generator (flow from dataframe)을 구현한다.


1. resnet50을 활용하여 image-net pretrained model을 불러온다.
2. Global average pooling layer를 추가한다.
3. Prediction layer 구성 (7가지의 Multi-class classification을 수행하는 모델을 구현)
-> 어떻게 activation function을 주어야 하는가?
-> Loss는 어떻게 줘서 compile 하여야 하느냐?

```python
# 기초 작업
batch_size = 10
epochs = 10
LearningRate = 3e-3
Decay = 1e-6
img_width = 224
img_height = 224

# 데이터 불러오기
Data = pd.read_csv("HAM10000_metadata.csv")
Data['image_id'] = Data['image_id'] + '.jpg'
Data = Data.sample(frac=1)
Data.head()

# Data augmentation
DATAGEN_TRAIN = ImageDataGenerator(
    rescale=1./255,
    rotation_range=15,
    width_shift_range=0.13,
    height_shift_range=0.13,
    shear_range=0.13,
    zoom_range=0.13, 
    horizontal_flip=True,
    vertical_flip=True,
    data_format="channels_last",
    brightness_range=[0.2,1.2],
    validation_split=0.10)

TRAIN_GENERATOR = DATAGEN_TRAIN.flow_from_dataframe(
    Data,
    directory='DATA_TRAIN',
    x_col='image_id',
    y_col='dx', 
    target_size=(img_height, img_width), 
    color_mode='rgb',
    class_mode='categorical', 
    batch_size=batch_size,
    shuffle=True,
    subset='training')

VALID_GENERATOR = DATAGEN_TRAIN.flow_from_dataframe(
    Data,
    directory='DATA_TRAIN',
    x_col='image_id',
    y_col='dx', 
    target_size=(img_height, img_width), 
    color_mode='rgb',
    class_mode='categorical', 
    batch_size=batch_size,
    shuffle=True,
    subset='validation')

# 모델 정의
ResNetModel = tf.keras.applications.ResNet50(
    include_top=False,
    weights='imagenet',
    input_tensor=None,
    input_shape=(img_width,img_height,3),
    pooling=None)

x = GlobalAveragePooling2D()(ResNetModel.output)

predictions = Dense(7, activation='softmax')(x)

DeepLearning = Model(inputs=ResNetModel.input, outputs=predictions)

DeepLearning.compile(optimizer='adam',
         loss='categorical_crossentropy',
         metrics=['acc']
)
# Test 
DATAGEN_TEST = ImageDataGenerator(
    rescale=1./255,
    data_format="channels_last")

TEST_GENERATOR = DATAGEN_TEST.flow_from_dataframe(
    Data,
    directory='DATA_TEST',
    x_col='image_id',
    y_col='dx', 
    target_size = (img_width, img_height),
    color_mode = 'rgb',
    batch_size = batch_size,
    shuffle = False,
    class_mode= "categorical")

# CALL BACK 함수

CP = ModelCheckpoint(filepath=MODEL_DIRECTORY+
                'ResNet50-sofrmax-{epoch:03d}-{loss:.4f}-{acc:.4f}-{val_loss:.4f}-{val_acc:.4f}.hdf5',
                monitor='val_loss', verbose=1, save_best_only=True, mode='min')
TB = TensorBoard(log_dir=TENSB_DIRECTORY, write_graph=True, write_images=True,profile_batch = 100000000)
LR = ReduceLROnPlateau(monitor='val_loss',factor=0.5,patience=5, verbose=1, min_lr=1e-8)
CALLBACK = [CP, TB, LR]

# 학습
DeepLearning.fit(
    TRAIN_GENERATOR,
    validation_data  = VALID_GENERATOR,
    epochs=3,
    callbacks=CALLBACK,
    shuffle=True)


# Class Activation Map 구현

# 가장 좋은 모델 가져오기
# 1. GAP 이후의 마지막 Fully-connected layer의 weight를 가져온다.
DeepLearning.load_weights("MODEL//ResNet50-Softmax-028-0.4848-0.8207-0.8499-0.7000.hdf5")
DeepLearning.evaluate(TEST_GENERATOR)

# CAM 모델
# 2. GAP 이전의 마지막 Convolutional layer의 input value를 가져온다.
CAM_MODEL = Model(inputs=DeepLearning.input, outputs=[DeepLearning.get_layer('conv5_block3_out').output, DeepLearning.output])

Image, Label = TEST_GENERATOR.__getitem__(0)

ConvOutput, Predicted = CAM_MODEL.predict(Images[:1])
print(Predicted.round(3))
ConvOutput = ConvOutput[0, :, :, :]
Weights = CAM_MODEL.get_layer('dense').get_weights()[0][:, 5]

Heatmaps = np.ndarray(shape=(7, 7), dtype='uint8')
for i in range(2048):
    Heatmaps = Heatmaps + ConvOutput[:, :, i] * Weights[i]

Heatmaps = cv2.resize(Heatmaps, (224, 224))
Heatmaps /= Heatmaps.max()

fig, ax = plt.subplots( nrows=1, ncols=2 ) 
fig.set_size_inches(6, 3.0)
ax = plt.subplot(1,2,1)
ax.imshow(Images[0])

ax = plt.subplot(1,2,2)
ax.imshow(Images[0])
ax.imshow(Heatmaps, cmap=plt.cm.jet, alpha=0.3, interpolation='nearest')
```